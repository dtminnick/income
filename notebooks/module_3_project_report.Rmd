---
title: "Predicting Income Level from Demographic and Behavioral Factors"
subtitle: "A Comparison of Linear Regression with an Indicator Matrix and Logistic Regression Approaches"
author: "Donnie Minnick, Statistical Learning - Fall A 2025"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
    theme:
      version: 4
      bootswatch: flatly
      primary: "#2C3E50"   # deep blue
      secondary: "#18BC9C" # accent teal
      base_font: "Arial"
      heading_font: "Calibri"
---

# Project Overview

This analysis evaluates two modeling approaches - linear regression with an indicator matrix and logistic regression - to determine which more reliably classifies individuals as earning above or below $50,000 per year. Using the [UCI Adult Income dataset](https://archive.ics.uci.edu/dataset/2/adult), the comparison focuses on practical performance measures including accuracy, sensitivity, specificity, and AUC. 

The goal is to identify the method that not only provides stronger predictive capability but also offers clearer insight into how demographic and employment attributes influence income levels.

## Analysis Question

How do linear regression with an indicator matrix and logistic regression compare in their ability to classify individuals as earning above or below $50,000 per year, based on demographic and employment attributes from the UCI Adult Income dataset, in terms of accuracy, sensitivity, specificity, and AUC?

## Data Suitability

The UCI Adult Income dataset is highly appropriate for this analysis because:

**Binary Target Variable**: The income label is already dichotomized as `<=50K` and `>50K`, making it ideal for classification tasks.

**Rich Feature Set**: It includes fourteen attributes spanning age, education, marital status, occupation, hours worked, and more, offering diverse predictors for modeling socioeconomic outcomes.

**Mixed Data Types**: The combination of categorical and continuous variables supports testing how each model handles encoding and feature interactions.

**Real-World Relevance**: The income threshold reflects a meaningful socioeconomic divide, making the classification task practically significant.

## Candidate Models

### Linear Regression with an Indicator Matrix

Linear regression, when applied with a binary indicator response, can be used to estimate probabilities of class membership. Although not traditionally designed for classification, it provides a straightforward benchmark and can reveal how continuous predictors like age or hours worked relate linearly to income. However, it may yield predictions outside the 0–1 range and does not naturally account for the probabilistic nature of binary outcomes.

### Logistic Regression

Logistic regression is a standard method for binary classification, modeling the log-odds of the outcome as a linear combination of predictors. It constrains predicted values between 0 and 1 and provides interpretable coefficients in terms of odds ratios. It is particularly well-suited for this problem and serves as the conventional baseline for evaluating newer or more complex classifiers.

### Why Compare?

Placing these two approaches side by side highlights the importance of choosing models that align with the data structure and research question. By comparing their performance on accuracy, sensitivity, specificity, and AUC, this analysis will demonstrate the trade-offs between a general-purpose regression method and a model purpose-built for classification.

### Baseline Expectations

Before conducting the analysis, it is important to establish expectations about how the candidate models are likely to perform:

**Logistic Regression Advantage**: Because logistic regression is specifically designed for binary classification, it is expected to outperform linear regression in terms of calibration and overall predictive reliability. Its ability to constrain predictions between 0 and 1 aligns naturally with the problem structure.

**Linear Regression Benchmark**: Linear regression with an indicator matrix may provide a useful baseline, but its predictions can extend outside the valid probability range and may not align as well with classification thresholds. Accuracy may be reasonable, but sensitivity and specificity are likely to suffer compared to logistic regression.

**Comparative Outlook**: Logistic regression is anticipated to deliver higher AUC and more balanced classification metrics, while linear regression may illustrate the pitfalls of applying a general-purpose model to a classification task. This contrast should highlight the importance of model choice in predictive analytics.

## Github Repo

All project files are maintained in [this Github repository](https://github.com/dtminnick/income).

## Code Libraries

The analysis leverages the following R packages: `caret` for model training and evaluation, `dplyr` for data manipulation, `knitr` for report formatting, and `pROC` for ROC/AUC analysis.

```{r, echo = FALSE}
library("caret")
library("dplyr")
library("ggplot2")
library("knitr")
library("pROC")
library("tidyr")
```

# Exploratory Data Analysis (Summary)



# Data Cleaning and Transformation

Load the income data.

```{r}
income <- readRDS("../data/income.rds")
```

## Missing Values

This code generates a report summarizing missing values in the dataset at both the column and row level. First, it counts missing values for each variable and calculates the percentage of missingness (col_missing). Then, it computes the total number and percentage of rows containing any missing values (row_missing). Finally, the two summaries are combined into a single table (missing_report) for easy inspection and reporting.

```{r}
# Create column level summary.

col_missing <- income %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(),
               names_to = "Variable",
               values_to = "Missing_Count") %>%
  mutate(Missing_Pct = Missing_Count / nrow(income) * 100)

# Create row level summary.

row_missing <- tibble(Variable = "Rows with any missing",
                      Missing_Count = sum(!complete.cases(income)),
                      Missing_Pct = sum(!complete.cases(income)) / nrow(income) * 100)

# Combine summaries.

missing_report <- bind_rows(col_missing, row_missing)

kable(missing_report,
      col.names = c("Variable", "Missing Count", "Missing Percent"),
      caption = "Missing Data",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```

Approximately 7.36% of rows (2,396 of 32,560) contain missing values, exclusively in the categorical variables related to work class, occupation, and native country. These values cannot be meaningfully imputed, so the affected rows will be removed from the dataset. Given the remaining 30,161 complete records, this approach preserves data integrity and is unlikely to impact model performance or statistical power.

```{r}
income <- income %>% drop_na()
```

## Redundancy

With 13 predictors in mixed types (nominal, ordinal, continuous), redundancy checks go beyond simple correlations. Here’s the structured approach I will follow.

### Check Multicollinearity Among Continuous Predictors

```{r}
cor(income[ , c("age_num",
                "years_of_education_num",
                "hours_per_week_num",
                "capital_gain_num", 
                "capital_loss_num")], 
    use = "pairwise.complete.obs")
```

### Assess Redundancy Among Categorical Predictors

Check associations among categorical variables

```{r}
nominal_vars <- c("workclass_num",
                  "marital_status_num",
                  "occupation_num",
                  "relationship_num",
                  "race_num",
                  "gender_num",
                  "native_country_num")

income[nominal_vars] <- lapply(income[nominal_vars], factor)

# Pairwise chi-square / Cramer's V
cat_pairs <- combn(nominal_vars, 2, simplify = FALSE)

for (pair in cat_pairs) {
  
  tab <- table(df[[pair[1]]], df[[pair[2]]])
  
  cv <- DescTools::CramerV(tab)
  
  cat("Cramer's V between", pair[1], "and", pair[2], ":", cv, "\n")
  
}
```

## Transformations

### Career Stage

I'll engineer a `career_stage` feature with four groups: 1) entry-level (ages 17-30), 2) growth phase (ages 31-45), 3) peak earning (ages 46-60, and 4) retirement transition (ages 61+).  See **Appendices | Appendix A: Exploratory Data Analysis | Age** section for rationale.

### Workclass Group

I'll engineer a `workclass_group` feature with four groups: 1) not employed, 2) self-employed, 3) government, and 4) private.  Will also address missing values.  See **Appendices | Appendix A: Exploratory Data Analysis | Workclass** section for rationale.

```{r}
income <- income %>%
  mutate(workclass_group = case_when(workclass_cat %in% c("Without-pay", "Never-worked") ~ "Not-employed",
                                     workclass_cat %in% c("Self-emp-inc", "Self-emp-not-inc") ~ "Self-employed",
                                     workclass_cat %in% c("Local-gov", "State-gov", "Federal-gov") ~ "Government",
                                     workclass_cat == "Private" ~ "Private",
                                     is.na(workclass_cat) | workclass_cat == "?" ~ "Unknown",
                                     TRUE ~ "Other"))
```

### Education Level (Ordinal Coding)

I'll use ordinal coding to treat education as a ranked factor to capture the income gradient.  I'll create a separate `education_level` variable for this as part of transformations.  See **Appendices | Appendix A: Exploratory Data Analysis | Education** section for rationale.

```{r}
education_levels <- c(
  "Preschool", "1st-4th", "5th-6th", "7th-8th", "9th", "10th", "11th", "12th",
  "HS-grad", "Some-college", "Assoc-voc", "Assoc-acdm",
  "Bachelors", "Masters", "Prof-school", "Doctorate"
)

income <- income %>%
  mutate(education_level_ord = factor(education_cat, levels = education_levels, ordered = TRUE))
```

### Years of Education

Years of education is essentially a numeric encoding of `education_cat` and the two are tightly coupled, i.e. each education category maps to a fixed number of years.  I'm already planning to use `education_level` and this variable will add no new information.  Including it risks multicollinearity, could inflate standard errors and obscure the true effect of education.  I'll exclude this variable as part of data transformations.

See **Appendices | Appendix A: Exploratory Data Analysis | Years of Education** section for rationale.

### Marital Group

Collapsing sparse categories may improve model stability and interpretability, e.g. married, non-traditional married, previously married, never married.  Will address as part of data transformations.

See **Appendices | Appendix A: Exploratory Data Analysis | Marital Status** section for rationale.

### Occupation Group

Will engineer a grouped variable for comparison purposes so that each group reflects a coherent socioeconomic role and to avoid categories with low counts.

See **Appendices | Appendix A: Exploratory Data Analysis | Occupation** section for rationale.

```{r}
income <- income %>%
  mutate(
    occupation_group = case_when(occupation_cat %in% c("Prof-specialty", 
                                                       "Exec-managerial") ~ "Professional/Managerial",
    occupation_cat %in% c("Craft-repair", 
                          "Transport-moving", 
                          "Machine-op-inspct", 
                          "Handlers-cleaners",
                          "Protective-serv", 
                          "Tech-support") ~ "Skilled Trades",
    occupation_cat %in% c("Adm-clerical", 
                          "Sales") ~ "Clerical/Sales",
    occupation_cat %in% c("Other-service", 
                          "Priv-house-serv") ~ "Service Roles",
    occupation_cat == "Farming-fishing" ~ "Agricultural",
    occupation_cat == "Armed-Forces" ~ "Military",
    is.na(occupation_cat) ~ "Missing/Unknown",
    TRUE ~ "Other"
    ))
```

### Hours Group

Implement hours-based segmentation could be a useful feature in models.  Treating an hours_group as ordered can capture what looks like a monotonic income trend.

See **Appendices | Appendix A: Exploratory Data Analysis | Hours Per Week** section for rationale.

```{r}
income <- incoime %>%
  mutate(hours_group = case_when(hours_per_week_num < 30 ~ "Underemployed",
                                 hours_per_week_num >= 30 & hours_per_week_num <= 45 ~ "Full-time",
                                 hours_per_week_num > 45 ~ "Overtime",
                                 TRUE ~ NA_character))
```

### Relationship Role

Engineer feature to bin relationships into relationship archetypes that are more gender neutral.

See **Appendices | Appendix A: Exploratory Data Analysis | Relationship** section for rationale.

```{r}
income <- income %>%
  mutate(relationship_role = case_when(
    relationship_cat %in% c("Husband", "Wife") & hours_per_week >= 40 ~ "Primary Earner",
    relationship_cat %in% c("Husband", "Wife") & hours_per_week < 40 ~ "Secondary Earner",
    relationship_cat %in% c("Not-in-family", "Unmarried") ~ "Independent Adult",
    relationship_cat %in% c("Own-child", "Other-relative") ~ "Dependent/Other",
    TRUE ~ "Unclassified"
  ))
```

### Race Income Score

An income-weighted race score is a way to numerically encode the average income propensity of each race group based on the observed data.  For each group, we can calculate the proportion of individuals earning greater than $50k.  That proportion becomes the score assigned to every individual in that race group.  It's a way of embedding group-level income behavior into a numeric feature.

See **Appendices | Appendix A: Exploratory Data Analysis | Race** section for rationale.

```{r}
race_income_rate <- income %>%
  group_by(race) %>%
  summarise(race_income_score = mean(income == ">50K"))

income <- income %>%
  left_join(race_income_rate, by = "race")
```

### Has Investment Activity

```{r}
income <- income %>%
  mutate(has_investment_activity = if_else(capital_gain > 0 | capital_loss > 0, 1, 0))
```

## Class Balance

We kept the natural 75/25 income split so predictions mirror real-world conditions. This ensures performance metrics are meaningful for decision-making, while still allowing models to be tuned for sensitivity and accuracy where it matters most.

# Split Data

The dataset is split into 60% training, 20% validation, and 20% test. This allocation provides enough data to train stable models while dedicating a higher-than-usual share to validation and testing. With a large dataset, this approach strengthens model comparison, improves tuning, and ensures that final performance metrics are based on a robust and representative holdout set.

To preserve representativeness, the data is split using stratified sampling so that the proportion of individuals earning `≤50K` and `>50K` remain consistent across the training, validation, and test sets.

```{r}
set.seed(123)

# Initial train/test split.

train_idx <- createDataPartition(income$income_below_num, p = 0.6, list = FALSE)

train <- income[train_idx, ]

temp  <- income[-train_idx, ]

# Split remaining into validation/test.

valid_idx <- createDataPartition(temp$income_below_num, p = 0.5, list = FALSE)

validation <- temp[valid_idx, ]

test <- temp[-valid_idx, ]
```

Check class balance.

```{r}
check_balance <- function(df, name) {
  df %>%
    count(income_below_num) %>%
    mutate(prop = round(n / sum(n), 2),
           dataset = name) %>%
    select(dataset,
           income_below_num, 
           n,
           prop)
}

check <- bind_rows(check_balance(train, "Train"),
                   check_balance(validation, "Validation"),
                   check_balance(test, "Test"))

kable(check,
      col.names = c("Dataset", "Income Level", "Count", "Percent"),
      caption = "Dataset Class Balance",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r", "r"))
```

# Train Models

## Linear Regression Indicator Matrix Model

We begin by preparing the predictor matrix X, containing numeric representations of age, education, and marital status. The response variable, income, is coded as 0 (≤$50K) or 1 (>$50K). We convert it to a one-hot (indicator) matrix Y for the multivariate linear regression.

```{r}
# Step 1: Prepare predictor matrix
X <- as.matrix(train[, c("age_num", "education_num", "marital_status_num")])

# Step 2: Create indicator matrix for binary response
G <- train$income_num  # Assumed to be 0/1
Y <- model.matrix(~ factor(G) - 1)  # One-hot encoding
```

A multivariate linear regression is fit with the one-hot encoded response matrix. This approach models the probability of each class as a linear combination of predictors.

```{r}
# Step 3: Fit multivariate linear regression
fit <- lm(Y ~ X)
```

Using the fitted model, we predict scores for each class. These predicted scores may fall outside the 0–1 range, which highlights the limitation of using linear regression for classification.

```{r}
# Step 4: Predict class scores
pred <- predict(fit, newdata = data.frame(X))
```

For each observation, we assign the class with the highest predicted score. We then recode it back to match the original binary labels (0 or 1).

```{r}
# Step 5: Assign predicted class (1 or 2)
class_pred <- max.col(pred)

# Step 6: Recode predicted class to match binary response (0/1)
class_pred_binary <- ifelse(class_pred == 1, 0, 1)
```

We evaluate the predicted classes against the true labels using a confusion matrix. Key metrics such as accuracy, sensitivity, specificity, and precision summarize the model’s performance.

```{r}
# Step 7: Evaluate classification performance
conf_mat <- caret::confusionMatrix(
  factor(class_pred_binary),
  factor(train$income_num)
)

# Step 8: Print metrics
conf_mat$overall["Accuracy"]
conf_mat$byClass[c("Sensitivity", "Specificity", "Precision")]
```

Although we can produce predicted classes and metrics, the predicted probabilities from a linear model are not constrained to [0,1]. This can result in nonsensical probabilities, motivating the use of logistic regression for binary outcomes.

### Extreme Probabilities

The table below summarizes the number and percentage of predicted probabilities from the linear regression model that fall outside the valid 0–1 range for each class. As expected, linear regression applied to a binary outcome can produce estimates below 0 or above 1, highlighting a limitation of this approach for classification tasks.

First, we extract the predicted probabilities for each class from the linear regression model. These probabilities represent the model’s estimated likelihood that each individual falls into the ≤$50K or >$50K income category.

```{r}
# Extract columns
prob_under50k <- pred[, "factor(G)0"]
prob_over50k  <- pred[, "factor(G)1"]
```

To assess the appropriateness of linear regression for a binary outcome, we identify predictions that fall outside the valid probability range of 0 to 1. The table below shows the number and percentage of such predictions for each class.

```{r}
# Count out-of-bounds for each class
out_under <- sum(prob_under50k < 0 | prob_under50k > 1)
out_over  <- sum(prob_over50k  < 0 | prob_over50k  > 1)
total <- nrow(pred)

# Summary table
data.frame(
  Class = c("<=50K", ">50K"),
  Out_of_Bounds = c(out_under, out_over),
  Total = total,
  Percent_Out_of_Bounds = round(100 * c(out_under, out_over) / total, 2)
)

# kable(check,
#       col.names = c("Dataset", "Income Level", "Count", "Percent"),
#       caption = "Dataset Class Balance",
#       format.args = list(big.mark = ","),
#       align = c("l", "r", "r", "r"))
```

The plot below illustrates the distribution of predicted probabilities for both income classes. The dashed red lines mark the valid 0–1 probability range. Any predictions beyond these boundaries are not interpretable as probabilities, demonstrating why logistic regression is generally preferred for binary classification problems.

```{r}
# Convert to long format for ggplot
df_long <- as.data.frame(pred) %>%
  pivot_longer(cols = everything(), names_to = "Class", values_to = "Probability")

# Plot
ggplot(df_long, aes(x = Probability, fill = Class)) +
  geom_histogram(bins = 50, color = "white", position = "dodge") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  labs(
    x = "Predicted Probability",
    y = "Count",
    title = "Distribution of Linear Regression Predicted Probabilities by Class"
  ) +
  scale_fill_manual(values = c("factor(G)0" = "steelblue", "factor(G)1" = "tomato")) +
  theme_minimal()
```

Together, these outputs provide a numeric indication and clear visual of the constraints of using linear regression for a categorical outcome, setting the stage for comparison with the logistic regression model.

### Generate ROC Curve and AUC Metric

```{r}
# Column 2 corresponds to class 1 (income_num == 1)
score_class1 <- pred[, 2]

roc_obj <- pROC::roc(response = train$income_num, predictor = score_class1)

# Plot ROC curve
plot(roc_obj, col = "blue", lwd = 2, main = "ROC Curve for Indicator Regression")

# AUC value
auc_value <- pROC::auc(roc_obj)
print(auc_value)

```

## Logistic Regression

```{r}
model_logistic <- glm(income_num ~ 
                        age_num + 
                        #workclass_num + 
                        education_num + 
                        marital_status_num,
                        #hours_per_week_num + 
                        #relationship_num + 
                        #race_num + 
                        #gender_num + 
                        #capital_gain_num + 
                        #capital_loss_num, 
                      data = train, family = "binomial")
```

### Generate Model Summary

```{r}
summary(model_logistic)
```

### Generate ROC Curve and AUC Metric

```{r}
train$predicted_prob <- predict(model_logistic, type = "response")

roc_obj <- pROC::roc(train$income_num, train$predicted_prob)

plot(roc_obj, col = "blue", main = "ROC Curve - Train Model")
```

```{r}
pROC::auc(roc_obj)
```

### Generate Confusion Matrix



```{r}
threshold <- 0.5

train$predicted_class <- ifelse(train$predicted_prob > 0.5, 1, 0)
```



```{r}
caret::confusionMatrix(factor(train$predicted_class), factor(train$income_num))
```

```{r}
confusion <- table(Predicted = train$predicted_class,
                   Actual = train$income_num)

TP <- confusion[2, 2]
FP <- confusion[2, 1]
FN <- confusion[1, 2]
TN <- confusion[1, 1]

sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
accuracy <- (TP + TN) / sum(confusion)

list(confusion = confusion,
     sensitivity = round(sensitivity, 2),
     specificity = round(specificity, 2),
     accuracy = round(accuracy, 2))
```

# Compare Models

## Training Data

## Validation Data

# Choose Final Model

# Retrain Final Model

# Evaluate Model

# Final Analysis

## Conclusions

## Challenges and Solutions

# Appendices

## Appendix A: Exploratory Data Analysis

### Age

```{r}
age <- income %>%
  group_by(age_num) %>%
  summarise(entries = n()) %>%
  mutate(percent = round(entries / sum(entries), 2))

kable(age,
      col.names = c("Age", "Entries", "Percent"),
      caption = "Age (age_num)",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```

This distribution mirrors what you'd expect from a working-age population in the US: a peak around age 20-30, reflecting a large cohort entering the workforce, a gradual decline through ages 40-50, typical of aging out of peak earning years or shifting to preparation for retirement, and dropoff after 60-50, reflecting retirement and reduced representation.

This pattern is clear when plotted.

```{r}
ggplot(age, aes(x = age_num, y = entries)) +
  geom_line(size = 1, color = "steelblue") +
  labs(title = "Distribution of Age (age_num)",
       x = "Age (age_num)",
       y = "Entries") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(age$entries) * 1.2)
```

Age is likely nonlinear in its relationship to income class.  Use binning to confirm this dynamic.

```{r}
# Step 1: Create age bins
income_age <- income %>%
  mutate(age_bin = cut(age_num, breaks = seq(15, 90, by = 5), include.lowest = TRUE))

# Calculate proportions within each age bin and income group
age_income_prop <- income_age %>%
  group_by(age_bin, income_cat) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(age_bin) %>%
  mutate(prop = count / sum(count))
```

Generate plot.

```{r}
ggplot(age_income_prop, aes(x = age_bin, y = prop, fill = income_cat)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_fill_manual(values = c("<=50K" = "lightsteelblue", ">50K" = "steelblue")) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Proportion of Income Classes by Age Group",
       x = "Age Group",
       y = "Proportion",
       fill = "Income Class") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(size = 14, face = "bold"))
```

This plot shows that income probability doesn't increase linearly with age; rather, it peaks mid-career and then drops.  I'll use a binning strategy to model this non-monotonic pattern, i.e. instead of assuming that each year of age adds the same effect, binning allows me to treat age as a set of behavioral groups.  

I'll engineer a `career_stage` feature with four groups: 1) entry-level (ages 17-30), 2) growth phase (ages 31-45), 3) peak earning (ages 46-60, and 4) retirement transition (ages 61+).

### Workclass

```{r}
workclass <- income %>%
  group_by(workclass_cat) %>%
  summarise(entries = n()) %>%
  mutate(percent = round(entries / sum(entries), 2))

kable(workclass,
      col.names = c("Workclass", "Entries", "Percent"),
      caption = "Workclass (workclass_cat, workclass_num)",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```



```{r}
ggplot(workclass, aes(x = forcats::fct_reorder(workclass_cat, entries, .desc = TRUE), y = entries)) +
  geom_col(fill = "steelblue", color = "white") +
  geom_text(aes(label = paste0(scales::comma(entries), "\n", round(percent * 100, 0), "%")),
            vjust = -0.3, size = 3.0) +
  labs(title = "Distribution of Workclass (workclass_cat, workclass_num)",
       x = "Workclass",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(workclass$entries) * 1.2)
```

With 64% of individuals in the Private workclass, the dataset is overwhelmingly skewed toward private-sector employment.  If we include `workclass` as a predictor, models may overfit to the private sector simply because it dominates the sample.  Minority categories will be underrepresented in predictions.  Coefficients for smaller workclasses may be unstable due to the low sample size.  And the private sector may mask behvaioral variation in other groups.

Visualize income class proportions by workclass to reveal whether private-sector dominance translates into higher earnings or just higher representation.

```{r}
income_by_workclass <- income %>%
  group_by(workclass_cat, income_cat) %>%
  summarise(n = n(), .groups = "drop") %>%
  group_by(workclass_cat) %>%
  mutate(prop = n / sum(n))
```

```{r}
ggplot(income_by_workclass, aes(x = workclass_cat, y = prop, fill = income_cat)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Income Distribution by Workclass",
    x = "Workclass",
    y = "Proportion",
    fill = "Income"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Based on this plot, the dominance of private workclass in the sample is not translating into dominance in income proportion.  

Despite being a small portion of the dataset, the Self-emp-inc workclass has the highest proportion of high-income earners.  This suggests that entrepreneurial ventures (when successful) yield higher income, but probably with higher variance.

While the private sector workclass dominates in count, its proportion of high-income earners is not the highest.  This could be a result of a wide range of roles, from lower-wage service jobs to higher-paying finance and technical roles.

The Federal-gov workclass shows a relatively strong proportion of high-income earners, perhaps due to structured pay scales that are common in government organizations.  The State-gov and Local-gov workclasses trail a bit, which probably reflects differences in funding.

The Without-pay and Never-worked workclasses are skewed to the low-income category, which is predictable.  These categories could be dropped or grouped as non-employed to avoid noise in classification models.

I'll engineer a `workclass_group` feature with four groups: 1) not employed, 2) self-employed, 3) government, and 4) private.  Will also address missing values.

### Education

```{r}
education <- income %>%
  group_by(education_num, education_cat) %>%
  summarise(entries = n(), .groups = "drop") %>%
  arrange(education_num) %>%
  mutate(percent = round(entries / sum(entries), 2),
         education_cat = factor(education_cat, levels = unique(education_cat)))


kable(education,
      col.names = c("Education Number", "Education Category", "Entries", "Percent"),
      caption = "Education (education_cat, education_num)",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```



```{r}
ggplot(education, aes(x = education_cat, y = entries)) +
  geom_col(fill = "steelblue", color = "white") +
  geom_text(aes(label = paste0(scales::comma(entries), "\n", round(percent * 100, 0), "%")),
            vjust = -0.3, size = 3.0) +
  labs(title = "Distribution of Workclass (workclass_cat, workclass_num)",
       x = "Workclass",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(education$entries) * 1.2)
```

High school graduates dominate the sample at 32%; this aligns with national trends.  The some-college a bachelors categories together make up 40% of the sample, indicating strong representation.  Advanced degrees are relatively rare; combined they account for ~7% of the sample, which could limit model ability to generalize to highly educated groups.  Low education levels are sparse; these are likely to be older adults or immigrants with limited formal schooling.

Plot income proportions by education.

```{r}

# Step 1: Count income levels per education
edu_order <- edu_income %>%
  filter(income_cat == ">50K") %>%
  arrange(desc(prop)) %>%
  pull(education_cat)


# Step 2: Calculate proportions
edu_income <- edu_income %>%
  mutate(education_cat = factor(education_cat, levels = edu_order))


# Step 3: Plot
ggplot(edu_income, aes(x = education_cat, y = prop, fill = income_cat)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Income Proportion by Education Level",
    x = "Education Level",
    y = "Proportion of Income Category",
    fill = "Income"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

There's an unmistakable pattern evident in this chart: the gradient from low education levels to advanced degress is a textbook example of socioecomonic stratification.  Still its surprising to see how nonlinear the payoff is.

High income really starts to dominate at the Bachelor level and is an inflection point for income potential.  Advanced degrees show the highest income potential, but this comes with investment of time and potentially debt as well.

I'll use ordinal coding to treat education as a ranked factor to capture the income gradient.  I'll create a separate `education_level` variable for this as part of transformations.

### Years of Education

```{r}
years_of_education <- income %>%
  group_by(years_of_education_num) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))


kable(years_of_education,
      col.names = c("Years of Education", "Entries", "Percent"),
      caption = "Years of Education (years_of_education_num)",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```

```{r}
ggplot(years_of_education, aes(x = years_of_education_num, y = entries)) +
  geom_col(fill = "steelblue", color = "white") +
  geom_text(aes(label = paste0(scales::comma(entries), "\n", round(percent * 100, 0), "%")),
            vjust = -0.3, size = 3.0) +
  labs(title = "Distribution of Years of Education (years_of_education)",
       x = "Years of Education",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(years_of_education$entries) * 1.2)
```

Years of education is essentially a numeric encoding of `education_cat` and the two are tightly coupled, i.e. each education category maps to a fixed number of years.  I'm already planning to use `education_level` and this variable will add no new information.  Including it risks multicollinearity, could inflate standard errors and obscure the true effect of education.  I'll exclude this variable as part of data transformations.

### Marital Status

```{r}
marital_status <- income %>%
  group_by(marital_status_cat) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))

kable(marital_status,
      col.names = c("Marital Status", "Entries", "Percent"),
      caption = "Marital Status (marital_status_cat, marital_status_num)",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```



```{r}
ggplot(marital_status, aes(x = forcats::fct_reorder(marital_status_cat, entries, .desc = TRUE), y = entries)) +
  geom_col(fill = "steelblue", color = "white") +
  geom_text(aes(label = paste0(scales::comma(entries), "\n", round(percent * 100, 0), "%")),
            vjust = -0.3, size = 3.0) +
  labs(title = "Distribution of Marital Status (marital_status_cat, marital_status_num)",
       x = "Marital Status",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(marital_status$entries) * 1.2)
```

Married-civ-spouse dominates at 46%.  Never-married follows at 33%.  The rest of the categories are smaller slices, but potentially behaviorally distinct.

Marital status could be a strong socioeconomic signal when predicting income, e.g. married individuals may benefit from dual incomes or household stability.  Never-married or separated individuals might reflect different life stages or economic pressures.

These categories are not ordinal, e.g. widowed or married is not more or less than divorced.

Collapsing sparse categories may improve model stability and interpretability, e.g. married, non-traditional married, previously married, never married.  Will address as part of data transformations.

### Occupation

```{r}
occupation <- income %>%
  group_by(occupation_cat) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))


kable(occupation,
      col.names = c("Occupation", "Entries", "Percent"),
      caption = "Occupation (occupation_cat, occupation_num)",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```



```{r}
ggplot(occupation, aes(x = forcats::fct_reorder(occupation_cat, entries, .desc = TRUE), y = entries)) +
  geom_col(fill = "steelblue", color = "white") +
  geom_text(aes(label = paste0(scales::comma(entries), "\n", round(percent * 100, 0), "%")),
            vjust = -0.3, size = 3.0) +
  labs(title = "Distribution of Occupation (occupation_cat, occupation_num)",
       x = "Occupation",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(occupation$entries) * 1.2)
```

The distribution is relatively balanced across several categories, with no single class dominating.  Occupation can serve as a proxy for income potential, job stability and education level.  Certain occupations skew toward higher income, while others may not.

With some low-frequency classes like armed-forces and privte-house-serv, grouping the categories can help stabilize models.  Will engineer a grouped variable for comparison purposes so that each group reflects a coherent socioeconomic role and to avoid categories with low counts.

| Group Name              | Included Categories             |
| ----------------------- | ------------------------------- |
| Professional/Managerial	| Prof-specialty, Exec-managerial |
| Skilled Trades          | Craft-repair, Transport-moving, Machine-op-inspct, Handlers-cleaners, Protective-serv, Tech-support |
| Clerical/Sales          | Adm-clerical, Sales             |
| Service Roles           |	Other-service, Priv-house-serv  | 
| Agricultural            |	Farming-fishing                 |
| Military                |	Armed-Forces                    |

### Hours Per Week

```{r}
hours_per_week <- income %>%
  group_by(hours_per_week_num) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))


kable(hours_per_week,
      col.names = c("Hours Per Week", "Entries", "Percent"),
      caption = "Hours Per Week (hours_per_week_num)",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```

```{r}
ggplot(hours_per_week, aes(x = hours_per_week_num, y = entries)) +
  geom_line(size = 1, color = "steelblue") +
  labs(title = "Distribution of Hours Per Week (hours_per_week_num)",
       x = "Hours Per Week",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(hours_per_week$entries) * 1.2)
```

There is a sharp and prominent spike at 40 hours, which can be considered a classic full-time benchmark in the US.  It dominates the dataset, reflecting standard employment contracts.  There are smaller peaks at 20, 30, 50 and 60 hours, suggesting common part-time and overtime thresholds.  These are potentially tied to specific industries or roles.  The jagged, irregular tail hints at self-reported data or job-specific norms, e.g. self-employment or gig work.

Treating this variable as continuous will miss behavioral inflection points described above.  Segmenting could better capture under-employment and overtime heavy roles, e.g. under-employment, less than 35 hours, standard full-time employment, 35-45 hours, and overtime-heavy, greater than 45 hours.

What is the proportion of high earners by hours group?

```{r}
income_by_hours_group <- income %>%
    mutate(hours_group = case_when(
    hours_per_week_num < 30 ~ "Underemployed",
    hours_per_week_num >= 30 & hours_per_week_num <= 45 ~ "Full-time",
    hours_per_week_num > 45 ~ "Overtime",
    TRUE ~ NA_character_
  )) %>%
  group_by(hours_group, income_cat) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(hours_group) %>%
  mutate(prop = count / sum(count))
  
ggplot(income_by_hours_group, aes(x = hours_group, y = prop, fill = income_cat)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Income Proportion by Hours Group",
    x = "Hours Group",
    y = "Proportion",
    fill = "Income Level"
  ) +
  theme_minimal()

```

The underemployed group is overwhelmingly low income and likely includes part-time, seasonal or precarious workers.  The full-time group is majority under $50k but has a noticeable uptick in high earners.  This suggests that full-time work alone isn't a guarantee of higher income.  The overtime group has the most balanced distribution; it probably includes a mix of skilled labor, self-employed individuals and salaried workers with performance incentives.

Hours-based segmentation could be a useful feature in models.  Treating an hours_group as ordered can capture what looks like a monotonic income trend.

### Relationship

```{r}
relationship <- income %>%
  group_by(relationship_cat) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))


kable(relationship,
      col.names = c("Relationship", "Entries", "Percent"),
      caption = "Relationship (relationship_cat, relationship_num)",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```

```{r}
ggplot(relationship, aes(x = forcats::fct_reorder(relationship_cat, entries, .desc = TRUE), y = entries)) +
  geom_col(fill = "steelblue", color = "white") +
  geom_text(aes(label = paste0(scales::comma(entries), "\n", round(percent * 100, 0), "%")),
            vjust = -0.3, size = 3.0) +
  labs(title = "Distribution of Relationship (relationship_cat, relationship_num)",
       x = "Relationship",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(relationship$entries) * 1.2)
```

Husband and not-in-family categories dominate the dataset.  Own-child likely reflects younger individuals or dependents.  The remaining categorties are smaller but distinct.  The distribution suggests that most individuals are either heads of household or living independently.

We need to treat this categorical variable as nominal and collapsing categories may stabilize estimates and improve interpretability.

Collapsing into: 1) spouse, 2) independent, 3) child, and 4) other potentially gives a cleaner variable with four behaviorally meaningful groups.

```{r}
income_by_relationship_group <- income %>%
  group_by(relationship_cat, income_cat) %>%
  summarise(count = n()) %>%
  mutate(prop = count / sum(count))
  # filter(income_cat == ">50K")

ggplot(income_by_relationship_group, aes(x = relationship_cat, y = prop, fill = income_cat)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Income Proportion by Relationship Group",
    x = "Relationship Group",
    y = "Proportion",
    fill = "Income Level"
  ) +
  theme_minimal()
```

The husband category has the highest proportion of high earning individuals; this aligns with traditional household structures where husbands are often primary earners.  The Own-child and Other-relative categories lag behind and likely represent dependents, students, or caretakers.  Not-in-family and Unmarried categories have a moderate proportion of high income earners.  These groups are likely to be behaviorally diverse, e.g. singles, cohabiters, roommates, etc.  The Wife category shows mid-level earnings as well; this may reflect secondary earners or part-time workers in dual-income households.  That said, assuming all wives are secondary earners does not hold.

Propose to engineer a feature to bin relationships into behavioral archetypes, e.g. primary earner, dependent, independent adult, etc.  This can reduce noise from sparse categories and enhance interpretability.

### Race

```{r}
race <- income %>%
  group_by(race_cat) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))


kable(race,
      col.names = c("Race", "Entries", "Percent"),
      caption = "Race",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```

```{r}
ggplot(race, aes(x = forcats::fct_reorder(race_cat, entries, .desc = TRUE), y = entries)) +
  geom_col(fill = "steelblue", color = "white") +
  geom_text(aes(label = paste0(scales::comma(entries), "\n", round(percent * 100, 0), "%")),
            vjust = -0.3, size = 3.0) +
  labs(title = "Distribution of Race",
       x = "Race",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(race$entries) * 1.2)
```

This plot shows that the White category is dominant in the data at 85%, while Black has a 10% representation and all other categories are sparse.  Any model trained on this data will be heavily influenced by the White category and may generalize poorly to other groups.

How does race intersect with income?

```{r}
race_income_counts <- income %>%
  group_by(race_cat, income_cat) %>%
  summarise(count = n(), .groups = "drop")

race_income_props <- race_income_counts %>%
  group_by(race_cat) %>%
  mutate(prop = count / sum(count))

ggplot(race_income_props, aes(x = race_cat, y = prop, fill = income_cat)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Income Proportions by Race",
       x = "Race", y = "Proportion",
       fill = "Income Level") +
  theme_minimal()
```

Asian-Pac-Islander has the highest proportion of high earners, White has the second highest proportion, and the remaining categories are predominantly low-income earners, which is potentially an indication of structural disadvantage or underrepresentation in high-income roles.

An income-weighted race score is a way to numerically encode the average income propensity of each race group based on the observed data.  For each group, we can calculate the proportion of individuals earning greater than $50k.  That proportion becomes the score assigned to every individual in that race group.  It's a way of embedding group-level income behavior into a numeric feature.  Will implement as a feature.

It can stablize sparse categories by embedding the income signal and improve interpretability without added complexity.  The score encodes the average proportion of individuals earning greater than $50k within each race category, i.e. it allows modeling of the effect of belonging to a group with a certain income tendency.

In a logistic regression model, it would be interpreted as, holding all other variables constant, the likelihood of being classified as a high-income earner based on the income tendency of the group to which the individual belongs.

### Gender

```{r}
gender <- income %>%
  group_by(gender_cat) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))


kable(gender,
      col.names = c("Gender", "Entries", "Percent"),
      caption = "Gender",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```

```{r}
ggplot(gender, aes(x = forcats::fct_reorder(gender_cat, entries, .desc = TRUE), y = entries)) +
  geom_col(fill = "steelblue", color = "white") +
  geom_text(aes(label = paste0(scales::comma(entries), "\n", round(percent * 100, 0), "%")),
            vjust = -0.3, size = 3.0) +
  labs(title = "Distribution of Gender",
       x = "Gender",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(gender$entries) * 1.2)
```

There is an imbalance between male and female representation in the data.  Male dominance means most income patterns will be shaped by male observations.  Female underrepresentation could lead to unstable estimates or biased predictions.  We can treat gender as a binary predictor, and if the models predict income better for males versus females, it may be overfitting the dominant group.

What does the distribution of income look like for males versus females?

```{r}
income_by_gender <- income %>%
  group_by(gender_cat, income_cat) %>%
  summarise(n = n()) %>%
  mutate(prop = n / sum(n))

ggplot(income_by_gender, aes(x = gender_cat, y = prop, fill = income_cat)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Proportion of Income Levels by Gender", y = "Proportion")

```

Male Income Split: A noticeable chunk of males earn >50K — visually, it looks like ~30–35%.

Female Income Split: The >50K segment is much smaller — likely ~10–15%.

The coral segment dominates both bars, but especially for females, suggesting a strong income disparity.

### Capital Gain

```{r}
capital_gain <- income %>%
  group_by(capital_gain_num) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))


kable(capital_gain,
      col.names = c("Capital Gain", "Entries", "Percent"),
      caption = "Capital Gain",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```

```{r}
ggplot(capital_gain, aes(x = capital_gain_num, y = entries)) +
  geom_line(size = 1, color = "steelblue") +
  labs(title = "Distribution of Capital Gain",
       x = "Capital Gain",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(capital_gain$entries) * 1.2)
```

Both capital gain and loss are heavily zero-inflated, and that skew makes them prime candidates for binary transformation. Here's a breakdown of why and how to do it:

Sparse signal: Most individuals have zero capital gain/loss, so the continuous values only apply to a small subset.

Model stability: Continuous skewed variables can distort coefficients or inflate variance in linear models.

Behavioral clarity: A binary flag captures the presence of investment activity, which may correlate with income or occupation.

### Capital Loss

```{r}
capital_loss <- income %>%
  group_by(capital_loss_num) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))


kable(capital_loss,
      col.names = c("Capital Loss", "Entries", "Percent"),
      caption = "Capital Loss",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```

```{r}
ggplot(capital_loss, aes(x = capital_loss_num, y = entries)) +
  geom_line(size = 1, color = "steelblue") +
  labs(title = "Distribution of Capital Loss",
       x = "Capital Loss",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1),
        plot.title = element_text(size = 14, face = "bold")) +
  expand_limits(y = max(capital_loss$entries) * 1.2)
```

Both capital gain and loss are heavily zero-inflated, and that skew makes them prime candidates for binary transformation. Here's a breakdown of why and how to do it:

Sparse signal: Most individuals have zero capital gain/loss, so the continuous values only apply to a small subset.

Model stability: Continuous skewed variables can distort coefficients or inflate variance in linear models.

Behavioral clarity: A binary flag captures the presence of investment activity, which may correlate with income or occupation.

You're looking at a cumulative distribution function (CDF) of capital loss, which tells you the proportion of individuals whose capital loss is less than or equal to a given value. Here's how to interpret the key features:

X-axis (Capital Loss): The dollar amount of capital loss.

Y-axis (Cumulative Proportion): The proportion of individuals with capital loss ≤ that amount.

```{r}
capital_loss %>%
  arrange(capital_loss_num) %>%
  mutate(cumulative = cumsum(entries) / sum(entries)) %>%
  ggplot(aes(x = capital_loss_num, y = cumulative)) +
  geom_line(color = "steelblue") +
  labs(title = "Cumulative Distribution of Capital Loss",
       x = "Capital Loss",
       y = "Cumulative Proportion") +
  theme_minimal()

```

Starts near 0.96: About 96% of individuals have zero capital loss.

Steep rise between ~1000 and ~2500: This is where most of the non-zero capital losses occur. The curve climbs quickly here, meaning a lot of the remaining 4% fall in this range.

Flattens after ~3000: Very few individuals have capital losses above this threshold. The curve approaching 1.00 means you've essentially captured the entire population by this point.

You might also treat it as a binary indicator (zero vs. non-zero) if the actual dollar amount isn’t predictive.

For fairness or interpretability, you could explore whether high capital losses correlate with other variables like income or age — but only for the small subset that experiences them.

### Native Country



```{r}
native_country <- income %>%
  group_by(native_country_cat) %>%
  summarise(entries = n(), .groups = "drop") %>%
  mutate(percent = round(entries / sum(entries), 2))


kable(native_country,
      col.names = c("Native Country", "Entries", "Percent"),
      caption = "Native Country",
      format.args = list(big.mark = ","),
      align = c("l", "r", "r"))
```







```{r}
# Dataset 1: US vs. All Others
native_country_us_vs_other <- native_country %>%
  mutate(group = ifelse(native_country_cat == "United-States", "United States", "Other")) %>%
  group_by(group) %>%
  summarise(entries = sum(entries), percent = sum(percent)) %>%
  ungroup()

# Dataset 2: All countries excluding US
native_country_non_us <- native_country %>%
  filter(native_country_cat != "United-States")

```

```{r}
ggplot(native_country_us_vs_other, aes(x = forcats::fct_reorder(group, percent, .desc = TRUE), y = percent)) +
  geom_col(fill = c("steelblue")) +
  geom_text(aes(label = paste0(round(percent * 100, 1), "%")),
            vjust = -0.3, size = 4.0) +
  labs(title = "Native Country: United States vs. All Others",
       x = NULL, y = "Percentage") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  expand_limits(y = max(native_country_us_vs_other$percent) * 1.2)

```



```{r}
native_country_grouped <- native_country %>%
  filter(native_country_cat != "United-States") %>%
  mutate(native_country_grouped = ifelse(percent < 0.01, "Other (<1%)", native_country_cat)) %>%
  group_by(native_country_grouped) %>%
  summarise(entries = sum(entries), percent = sum(percent)) %>%
  ungroup()

```

```{r}
ggplot(native_country_grouped, aes(y = forcats::fct_reorder(native_country_grouped, percent), x = percent)) +
  geom_col(fill = "steelblue") +
  geom_text(aes(label = paste0(round(percent * 100, 1), "%")),
            hjust = -0.1, size = 3.0) +
  labs(title = "Native Country: All Non-US (Grouped <1%)",
       x = "Percentage", y = "Native Country") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold")) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  expand_limits(x = max(native_country_grouped$percent) * 1.1)

```













